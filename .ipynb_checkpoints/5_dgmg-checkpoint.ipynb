{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tutorial for Generative Models of Graphs\n",
    "===========================================\n",
    "\n",
    "**Author**: `Mufei Li <https://github.com/mufeili>`_,\n",
    "`Lingfan Yu <https://github.com/ylfdq1118>`_, Zheng Zhang\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In earlier tutorials we have seen how learned embedding of a graph and/or\n",
    "a node allow applications such as `semi-supervised classification for nodes\n",
    "<http://docs.dgl.ai/tutorials/models/1_gcn.html#sphx-glr-tutorials-models-1-gcn-py>`__\n",
    "or `sentiment analysis\n",
    "<http://docs.dgl.ai/tutorials/models/3_tree-lstm.html#sphx-glr-tutorials-models-3-tree-lstm-py>`__.\n",
    "Wouldn't it be interesting to predict the future evolution of the graph and\n",
    "perform the analysis iteratively?\n",
    "\n",
    "We will need to generate a variety of graph samples, in other words, we need\n",
    "**generative models** of graphs. Instead of and/or in addition to learning\n",
    "node and edge features, we want to model the distribution of arbitrary graphs.\n",
    "While general generative models can model the density function explicitly and\n",
    "implicitly and generate samples at once or sequentially, we will only focus\n",
    "on explicit generative models for sequential generation here. Typical applications\n",
    "include drug/material discovery, chemical processes, proteomics, etc.\n",
    "\n",
    "Introduction\n",
    "--------------------\n",
    "The primitive actions of mutating a graph in DGL are nothing more than ``add_nodes``\n",
    "and ``add_edges``. That is, if we were to draw a circle of 3 nodes,\n",
    "\n",
    ".. figure:: https://user-images.githubusercontent.com/19576924/48313438-78baf000-e5f7-11e8-931e-cd00ab34fa50.gif\n",
    "   :alt:\n",
    "\n",
    "we can simply write the code as:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "g = dgl.DGLGraph()\n",
    "g.add_nodes(1)              # Add node 0\n",
    "g.add_nodes(1)              # Add node 1\n",
    "\n",
    "# Edges in DGLGraph are directed by default.\n",
    "# For undirected edges, we add edges for both directions.\n",
    "g.add_edges([1, 0], [0, 1]) # Add edges (1, 0), (0, 1)\n",
    "g.add_nodes(1)              # Add node 2\n",
    "g.add_edges([2, 1], [1, 2]) # Add edges (2, 1), (1, 2)\n",
    "g.add_edges([2, 0], [0, 2]) # Add edges (2, 0), (0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world graphs are much more complex. There are many families of graphs,\n",
    "with different sizes, topologies, node types, edge types, and the possibility\n",
    "of multigraphs. Besides, a same graph can be generated in many different\n",
    "orders. Regardless, the generative process entails a few steps:\n",
    "\n",
    "- Encode a changing graph,\n",
    "- Perform actions stochastically,\n",
    "- Collect error signals and optimize the model parameters (If we are training)\n",
    "\n",
    "When it comes to implementation, another important aspect is speed: how do we\n",
    "parallelize the computation given that generating a graph is fundamentally a\n",
    "sequential process?\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>To be sure, this is not necessarily a hard constraint, one can imagine\n",
    "   that subgraphs can be built in parallel and then get assembled. But we\n",
    "   will restrict ourselves to the sequential processes for this tutorial.</p></div>\n",
    "\n",
    "In tutorial, we will first focus on how to train and generate one graph at\n",
    "a time, exploring parallelism within the graph embedding operation, an\n",
    "essential building block. We will end with a simple optimization that\n",
    "delivers a 2x speedup by batching across graphs.\n",
    "\n",
    "DGMG: the main flow\n",
    "--------------------\n",
    "We pick DGMG (\n",
    "`Learning Deep Generative Models of Graphs <https://arxiv.org/abs/1803.03324>`__\n",
    ") as an exercise to implement a graph generative model using DGL, primarily\n",
    "because its algorithmic framework is general but also challenging to parallelize.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>While it's possible for DGMG to handle complex graphs with typed nodes,\n",
    "   typed edges and multigraphs, we only present a simplified version of it\n",
    "   for generating graph topologies.</p></div>\n",
    "\n",
    "DGMG generates a graph by following a state machine, which is basically a\n",
    "two-level loop:  generate one node at a time, and connect it to a subset of\n",
    "the existing nodes, one at a time. This is similar to language modeling: the\n",
    "generative process is an iterative one that emits one word/character/sentence\n",
    "at a time, conditioned on the sequence generated so far.\n",
    "\n",
    "At each time step, we either\n",
    "     - add a new node to the graph, or\n",
    "     - select two existing nodes and add an edge between them\n",
    "\n",
    ".. figure:: https://user-images.githubusercontent.com/19576924/48605003-7f11e900-e9b6-11e8-8880-87362348e154.png\n",
    "   :alt:\n",
    "\n",
    "The Python code will look as follows; in fact, this is *exactly* how inference\n",
    "with DGMG is implemented in DGL:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_inference(self):\n",
    "    stop = self.add_node_and_update()\n",
    "    while (not stop) and (self.g.number_of_nodes() < self.v_max + 1):\n",
    "        num_trials = 0\n",
    "        to_add_edge = self.add_edge_or_not()\n",
    "        while to_add_edge and (num_trials < self.g.number_of_nodes() - 1):\n",
    "            self.choose_dest_and_update()\n",
    "            num_trials += 1\n",
    "            to_add_edge = self.add_edge_or_not()\n",
    "        stop = self.add_node_and_update()\n",
    "\n",
    "    return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have a pre-trained model for generating cycles of nodes 10 - 20, let's see\n",
    "how it generates a cycle on the fly during inference. You can also use the code below\n",
    "for creating animation with your own model.\n",
    "\n",
    "::\n",
    "\n",
    "    import torch\n",
    "    import matplotlib.animation as animation\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        # pre-trained model saved with path ./model.pth\n",
    "        model = torch.load('./model.pth')\n",
    "        model.eval()\n",
    "        g = model()\n",
    "\n",
    "        src_list = g.edges()[1]\n",
    "        dest_list = g.edges()[0]\n",
    "\n",
    "        evolution = []\n",
    "\n",
    "        nx_g = nx.Graph()\n",
    "        evolution.append(deepcopy(nx_g))\n",
    "\n",
    "        for i in range(0, len(src_list), 2):\n",
    "            src = src_list[i].item()\n",
    "            dest = dest_list[i].item()\n",
    "            if src not in nx_g.nodes():\n",
    "                nx_g.add_node(src)\n",
    "                evolution.append(deepcopy(nx_g))\n",
    "            if dest not in nx_g.nodes():\n",
    "                nx_g.add_node(dest)\n",
    "                evolution.append(deepcopy(nx_g))\n",
    "            nx_g.add_edges_from([(src, dest), (dest, src)])\n",
    "            evolution.append(deepcopy(nx_g))\n",
    "\n",
    "        def animate(i):\n",
    "            ax.cla()\n",
    "            g_t = evolution[i]\n",
    "            nx.draw_circular(g_t, with_labels=True, ax=ax,\n",
    "                             node_color=['#FEBD69'] * g_t.number_of_nodes())\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ani = animation.FuncAnimation(fig, animate,\n",
    "                                      frames=len(evolution),\n",
    "                                      interval=600)\n",
    "\n",
    ".. figure:: https://user-images.githubusercontent.com/19576924/48928548-2644d200-ef1b-11e8-8591-da93345382ad.gif\n",
    "   :alt:\n",
    "\n",
    "DGMG: optimization objective\n",
    "------------------------------\n",
    "Similar to language modeling, DGMG trains the model with *behavior cloning*,\n",
    "or *teacher forcing*. Let's assume for each graph there exists a sequence of\n",
    "*oracle actions* $a_{1},\\cdots,a_{T}$ that generates it. What the model\n",
    "does is to follow these actions, compute the joint probabilities of such\n",
    "action sequences, and maximize them.\n",
    "\n",
    "By chain rule, the probability of taking $a_{1},\\cdots,a_{T}$ is:\n",
    "\n",
    "\\begin{align}p(a_{1},\\cdots, a_{T}) = p(a_{1})p(a_{2}|a_{1})\\cdots p(a_{T}|a_{1},\\cdots,a_{T-1}).\\\\\\end{align}\n",
    "\n",
    "The optimization objective is then simply the typical MLE loss:\n",
    "\n",
    "\\begin{align}-\\log p(a_{1},\\cdots,a_{T})=-\\sum_{t=1}^{T}\\log p(a_{t}|a_{1},\\cdots, a_{t-1}).\\\\\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_train(self, actions):\n",
    "    \"\"\"\n",
    "    - actions: list\n",
    "        - Contains a_1, ..., a_T described above\n",
    "    - self.prepare_for_train()\n",
    "        - Initializes self.action_step to be 0, which will get\n",
    "          incremented by 1 every time it is called.\n",
    "        - Initializes objects recording log p(a_t|a_1,...a_{t-1})\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - self.get_log_prob(): log p(a_1, ..., a_T)\n",
    "    \"\"\"\n",
    "    self.prepare_for_train()\n",
    "\n",
    "    stop = self.add_node_and_update(a=actions[self.action_step])\n",
    "    while not stop:\n",
    "        to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
    "        while to_add_edge:\n",
    "            self.choose_dest_and_update(a=actions[self.action_step])\n",
    "            to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n",
    "        stop = self.add_node_and_update(a=actions[self.action_step])\n",
    "\n",
    "    return self.get_log_prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between ``forward_train`` and ``forward_inference`` is\n",
    "that the training process takes oracle actions as input, and returns log\n",
    "probabilities for evaluating the loss.\n",
    "\n",
    "DGMG: the implementation\n",
    "--------------------------\n",
    "The ``DGMG`` class\n",
    "``````````````````````````\n",
    "Below one can find the skeleton code for the model. We will gradually\n",
    "fill in the details for each function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DGMGSkeleton(nn.Module):\n",
    "    def __init__(self, v_max):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        v_max: int\n",
    "            Max number of nodes considered\n",
    "        \"\"\"\n",
    "        super(DGMGSkeleton, self).__init__()\n",
    "\n",
    "        # Graph configuration\n",
    "        self.v_max = v_max\n",
    "\n",
    "    def add_node_and_update(self, a=None):\n",
    "        \"\"\"Decide if to add a new node.\n",
    "        If a new node should be added, update the graph.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def add_edge_or_not(self, a=None):\n",
    "        \"\"\"Decide if a new edge should be added.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def choose_dest_and_update(self, a=None):\n",
    "        \"\"\"Choose destination and connect it to the latest node.\n",
    "        Add edges for both directions and update the graph.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def forward_train(self, actions):\n",
    "        \"\"\"Forward at training time. It records the probability\n",
    "        of generating a ground truth graph following the actions.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def forward_inference(self):\n",
    "        \"\"\"Forward at inference time.\n",
    "        It generates graphs on the fly.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def forward(self, actions=None):\n",
    "        # The graph we will work on\n",
    "        self.g = dgl.DGLGraph()\n",
    "\n",
    "        # If there are some features for nodes and edges,\n",
    "        # zero tensors will be set for those of new nodes and edges.\n",
    "        self.g.set_n_initializer(dgl.frame.zero_initializer)\n",
    "        self.g.set_e_initializer(dgl.frame.zero_initializer)\n",
    "\n",
    "        if self.training:\n",
    "            return self.forward_train(actions=actions)\n",
    "        else:\n",
    "            return self.forward_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding a dynamic graph\n",
    "``````````````````````````\n",
    "All the actions generating a graph are sampled from probability\n",
    "distributions. In order to do that, we must project the structured data,\n",
    "namely the graph, onto an Euclidean space. The challenge is that such\n",
    "process, called *embedding*, needs to be repeated as the graphs mutate.\n",
    "\n",
    "Graph Embedding\n",
    "''''''''''''''''''''''''''\n",
    "Let $G=(V,E)$ be an arbitrary graph. Each node $v$ has an\n",
    "embedding vector $\\textbf{h}_{v} \\in \\mathbb{R}^{n}$. Similarly,\n",
    "the graph has an embedding vector $\\textbf{h}_{G} \\in \\mathbb{R}^{k}$.\n",
    "Typically, $k > n$ since a graph contains more information than\n",
    "an individual node.\n",
    "\n",
    "The graph embedding is a weighted sum of node embeddings under a linear\n",
    "transformation:\n",
    "\n",
    "\\begin{align}\\textbf{h}_{G} =\\sum_{v\\in V}\\text{Sigmoid}(g_m(\\textbf{h}_{v}))f_{m}(\\textbf{h}_{v}),\\\\\\end{align}\n",
    "\n",
    "The first term, $\\text{Sigmoid}(g_m(\\textbf{h}_{v}))$, computes a\n",
    "gating function and can be thought as how much the overall graph embedding\n",
    "attends on each node. The second term $f_{m}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{k}$\n",
    "maps the node embeddings to the space of graph embeddings.\n",
    "\n",
    "We implement graph embedding as a ``GraphEmbed`` class:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class GraphEmbed(nn.Module):\n",
    "    def __init__(self, node_hidden_size):\n",
    "        super(GraphEmbed, self).__init__()\n",
    "\n",
    "        # Setting from the paper\n",
    "        self.graph_hidden_size = 2 * node_hidden_size\n",
    "\n",
    "        # Embed graphs\n",
    "        self.node_gating = nn.Sequential(\n",
    "            nn.Linear(node_hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.node_to_graph = nn.Linear(node_hidden_size,\n",
    "                                       self.graph_hidden_size)\n",
    "\n",
    "    def forward(self, g):\n",
    "        if g.number_of_nodes() == 0:\n",
    "            return torch.zeros(1, self.graph_hidden_size)\n",
    "        else:\n",
    "            # Node features are stored as hv in ndata.\n",
    "            hvs = g.ndata['hv']\n",
    "            return (self.node_gating(hvs) *\n",
    "                    self.node_to_graph(hvs)).sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update node embeddings via graph propagation\n",
    "''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "The mechanism of updating node embeddings in DGMG is similar to that for\n",
    "graph convolutional networks. For a node $v$ in the graph, its\n",
    "neighbor $u$ sends a message to it with\n",
    "\n",
    "\\begin{align}\\textbf{m}_{u\\rightarrow v}=\\textbf{W}_{m}\\text{concat}([\\textbf{h}_{v}, \\textbf{h}_{u}, \\textbf{x}_{u, v}]) + \\textbf{b}_{m},\\\\\\end{align}\n",
    "\n",
    "where $\\textbf{x}_{u,v}$ is the embedding of the edge between\n",
    "$u$ and $v$.\n",
    "\n",
    "After receiving messages from all its neighbors, $v$ summarizes them\n",
    "with a node activation vector\n",
    "\n",
    "\\begin{align}\\textbf{a}_{v} = \\sum_{u: (u, v)\\in E}\\textbf{m}_{u\\rightarrow v}\\\\\\end{align}\n",
    "\n",
    "and use this information to update its own feature:\n",
    "\n",
    "\\begin{align}\\textbf{h}'_{v} = \\textbf{GRU}(\\textbf{h}_{v}, \\textbf{a}_{v}).\\\\\\end{align}\n",
    "\n",
    "Performing all the operations above once for all nodes synchronously is\n",
    "called one round of graph propagation. The more rounds of graph propagation\n",
    "we perform, the longer distance messages travel throughout the graph.\n",
    "\n",
    "With dgl, we implement graph propagation with ``g.update_all``. Note that\n",
    "the message notation here can be a bit confusing. While the authors refer\n",
    "to $\\textbf{m}_{u\\rightarrow v}$ as messages, our message function\n",
    "below only passes $\\text{concat}([\\textbf{h}_{u}, \\textbf{x}_{u, v}])$.\n",
    "The operation $\\textbf{W}_{m}\\text{concat}([\\textbf{h}_{v}, \\textbf{h}_{u}, \\textbf{x}_{u, v}]) + \\textbf{b}_{m}$\n",
    "is then performed across all edges at once for efficiency consideration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class GraphProp(nn.Module):\n",
    "    def __init__(self, num_prop_rounds, node_hidden_size):\n",
    "        super(GraphProp, self).__init__()\n",
    "\n",
    "        self.num_prop_rounds = num_prop_rounds\n",
    "\n",
    "        # Setting from the paper\n",
    "        self.node_activation_hidden_size = 2 * node_hidden_size\n",
    "\n",
    "        message_funcs = []\n",
    "        node_update_funcs = []\n",
    "        self.reduce_funcs = []\n",
    "\n",
    "        for t in range(num_prop_rounds):\n",
    "            # input being [hv, hu, xuv]\n",
    "            message_funcs.append(nn.Linear(2 * node_hidden_size + 1,\n",
    "                                           self.node_activation_hidden_size))\n",
    "\n",
    "            self.reduce_funcs.append(partial(self.dgmg_reduce, round=t))\n",
    "            node_update_funcs.append(\n",
    "                nn.GRUCell(self.node_activation_hidden_size,\n",
    "                           node_hidden_size))\n",
    "\n",
    "        self.message_funcs = nn.ModuleList(message_funcs)\n",
    "        self.node_update_funcs = nn.ModuleList(node_update_funcs)\n",
    "\n",
    "    def dgmg_msg(self, edges):\n",
    "        \"\"\"For an edge u->v, return concat([h_u, x_uv])\"\"\"\n",
    "        return {'m': torch.cat([edges.src['hv'],\n",
    "                                edges.data['he']],\n",
    "                               dim=1)}\n",
    "\n",
    "    def dgmg_reduce(self, nodes, round):\n",
    "        hv_old = nodes.data['hv']\n",
    "        m = nodes.mailbox['m']\n",
    "        message = torch.cat([\n",
    "            hv_old.unsqueeze(1).expand(-1, m.size(1), -1), m], dim=2)\n",
    "        node_activation = (self.message_funcs[round](message)).sum(1)\n",
    "\n",
    "        return {'a': node_activation}\n",
    "\n",
    "    def forward(self, g):\n",
    "        if g.number_of_edges() > 0:\n",
    "            for t in range(self.num_prop_rounds):\n",
    "                g.update_all(message_func=self.dgmg_msg,\n",
    "                             reduce_func=self.reduce_funcs[t])\n",
    "                g.ndata['hv'] = self.node_update_funcs[t](\n",
    "                     g.ndata['a'], g.ndata['hv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions\n",
    "``````````````````````````\n",
    "All actions are sampled from distributions parameterized using neural nets\n",
    "and we introduce them in turn.\n",
    "\n",
    "Action 1: add nodes\n",
    "''''''''''''''''''''''''''\n",
    "\n",
    "Given the graph embedding vector $\\textbf{h}_{G}$, we evaluate\n",
    "\n",
    "\\begin{align}\\text{Sigmoid}(\\textbf{W}_{\\text{add node}}\\textbf{h}_{G}+b_{\\text{add node}}),\\\\\\end{align}\n",
    "\n",
    "which is then used to parametrize a Bernoulli distribution for deciding whether\n",
    "to add a new node.\n",
    "\n",
    "If a new node is to be added, we initialize its feature with\n",
    "\n",
    "\\begin{align}\\textbf{W}_{\\text{init}}\\text{concat}([\\textbf{h}_{\\text{init}} , \\textbf{h}_{G}])+\\textbf{b}_{\\text{init}},\\\\\\end{align}\n",
    "\n",
    "where $\\textbf{h}_{\\text{init}}$ is a learnable embedding module for\n",
    "untyped nodes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "def bernoulli_action_log_prob(logit, action):\n",
    "    \"\"\"Calculate the log p of an action with respect to a Bernoulli\n",
    "    distribution. Use logit rather than prob for numerical stability.\"\"\"\n",
    "    if action == 0:\n",
    "        return F.logsigmoid(-logit)\n",
    "    else:\n",
    "        return F.logsigmoid(logit)\n",
    "\n",
    "class AddNode(nn.Module):\n",
    "    def __init__(self, graph_embed_func, node_hidden_size):\n",
    "        super(AddNode, self).__init__()\n",
    "\n",
    "        self.graph_op = {'embed': graph_embed_func}\n",
    "\n",
    "        self.stop = 1\n",
    "        self.add_node = nn.Linear(graph_embed_func.graph_hidden_size, 1)\n",
    "\n",
    "        # If to add a node, initialize its hv\n",
    "        self.node_type_embed = nn.Embedding(1, node_hidden_size)\n",
    "        self.initialize_hv = nn.Linear(node_hidden_size + \\\n",
    "                                       graph_embed_func.graph_hidden_size,\n",
    "                                       node_hidden_size)\n",
    "\n",
    "        self.init_node_activation = torch.zeros(1, 2 * node_hidden_size)\n",
    "\n",
    "    def _initialize_node_repr(self, g, node_type, graph_embed):\n",
    "        \"\"\"Whenver a node is added, initialize its representation.\"\"\"\n",
    "        num_nodes = g.number_of_nodes()\n",
    "        hv_init = self.initialize_hv(\n",
    "            torch.cat([\n",
    "                self.node_type_embed(torch.LongTensor([node_type])),\n",
    "                graph_embed], dim=1))\n",
    "        g.nodes[num_nodes - 1].data['hv'] = hv_init\n",
    "        g.nodes[num_nodes - 1].data['a'] = self.init_node_activation\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, action=None):\n",
    "        graph_embed = self.graph_op['embed'](g)\n",
    "\n",
    "        logit = self.add_node(graph_embed)\n",
    "        prob = torch.sigmoid(logit)\n",
    "\n",
    "        if not self.training:\n",
    "            action = Bernoulli(prob).sample().item()\n",
    "        stop = bool(action == self.stop)\n",
    "\n",
    "        if not stop:\n",
    "            g.add_nodes(1)\n",
    "            self._initialize_node_repr(g, action, graph_embed)\n",
    "\n",
    "        if self.training:\n",
    "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
    "\n",
    "            self.log_prob.append(sample_log_prob)\n",
    "\n",
    "        return stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action 2: add edges\n",
    "''''''''''''''''''''''''''\n",
    "\n",
    "Given the graph embedding vector $\\textbf{h}_{G}$ and the node\n",
    "embedding vector $\\textbf{h}_{v}$ for the latest node $v$,\n",
    "we evaluate\n",
    "\n",
    "\\begin{align}\\text{Sigmoid}(\\textbf{W}_{\\text{add edge}}\\text{concat}([\\textbf{h}_{G}, \\textbf{h}_{v}])+b_{\\text{add edge}}),\\\\\\end{align}\n",
    "\n",
    "which is then used to parametrize a Bernoulli distribution for deciding\n",
    "whether to add a new edge starting from $v$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddEdge(nn.Module):\n",
    "    def __init__(self, graph_embed_func, node_hidden_size):\n",
    "        super(AddEdge, self).__init__()\n",
    "\n",
    "        self.graph_op = {'embed': graph_embed_func}\n",
    "        self.add_edge = nn.Linear(graph_embed_func.graph_hidden_size + \\\n",
    "                                  node_hidden_size, 1)\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, action=None):\n",
    "        graph_embed = self.graph_op['embed'](g)\n",
    "        src_embed = g.nodes[g.number_of_nodes() - 1].data['hv']\n",
    "\n",
    "        logit = self.add_edge(torch.cat(\n",
    "            [graph_embed, src_embed], dim=1))\n",
    "        prob = torch.sigmoid(logit)\n",
    "\n",
    "        if self.training:\n",
    "            sample_log_prob = bernoulli_action_log_prob(logit, action)\n",
    "            self.log_prob.append(sample_log_prob)\n",
    "        else:\n",
    "            action = Bernoulli(prob).sample().item()\n",
    "\n",
    "        to_add_edge = bool(action == 0)\n",
    "        return to_add_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action 3: choosing destination\n",
    "'''''''''''''''''''''''''''''''''\n",
    "\n",
    "When action 2 returns True, we need to choose a destination for the\n",
    "latest node $v$.\n",
    "\n",
    "For each possible destination $u\\in\\{0, \\cdots, v-1\\}$, the\n",
    "probability of choosing it is given by\n",
    "\n",
    "\\begin{align}\\frac{\\text{exp}(\\textbf{W}_{\\text{dest}}\\text{concat}([\\textbf{h}_{u}, \\textbf{h}_{v}])+\\textbf{b}_{\\text{dest}})}{\\sum_{i=0}^{v-1}\\text{exp}(\\textbf{W}_{\\text{dest}}\\text{concat}([\\textbf{h}_{i}, \\textbf{h}_{v}])+\\textbf{b}_{\\text{dest}})}\\\\\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "class ChooseDestAndUpdate(nn.Module):\n",
    "    def __init__(self, graph_prop_func, node_hidden_size):\n",
    "        super(ChooseDestAndUpdate, self).__init__()\n",
    "\n",
    "        self.graph_op = {'prop': graph_prop_func}\n",
    "        self.choose_dest = nn.Linear(2 * node_hidden_size, 1)\n",
    "\n",
    "    def _initialize_edge_repr(self, g, src_list, dest_list):\n",
    "        # For untyped edges, we only add 1 to indicate its existence.\n",
    "        # For multiple edge types, we can use a one hot representation\n",
    "        # or an embedding module.\n",
    "        edge_repr = torch.ones(len(src_list), 1)\n",
    "        g.edges[src_list, dest_list].data['he'] = edge_repr\n",
    "\n",
    "    def prepare_training(self):\n",
    "        self.log_prob = []\n",
    "\n",
    "    def forward(self, g, dest):\n",
    "        src = g.number_of_nodes() - 1\n",
    "        possible_dests = range(src)\n",
    "\n",
    "        src_embed_expand = g.nodes[src].data['hv'].expand(src, -1)\n",
    "        possible_dests_embed = g.nodes[possible_dests].data['hv']\n",
    "\n",
    "        dests_scores = self.choose_dest(\n",
    "            torch.cat([possible_dests_embed,\n",
    "                       src_embed_expand], dim=1)).view(1, -1)\n",
    "        dests_probs = F.softmax(dests_scores, dim=1)\n",
    "\n",
    "        if not self.training:\n",
    "            dest = Categorical(dests_probs).sample().item()\n",
    "\n",
    "        if not g.has_edge_between(src, dest):\n",
    "            # For undirected graphs, we add edges for both directions\n",
    "            # so that we can perform graph propagation.\n",
    "            src_list = [src, dest]\n",
    "            dest_list = [dest, src]\n",
    "\n",
    "            g.add_edges(src_list, dest_list)\n",
    "            self._initialize_edge_repr(g, src_list, dest_list)\n",
    "\n",
    "            self.graph_op['prop'](g)\n",
    "\n",
    "        if self.training:\n",
    "            if dests_probs.nelement() > 1:\n",
    "                self.log_prob.append(\n",
    "                    F.log_softmax(dests_scores, dim=1)[:, dest: dest + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it together\n",
    "``````````````````````````\n",
    "\n",
    "We are now ready to have a complete implementation of the model class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGMG(DGMGSkeleton):\n",
    "    def __init__(self, v_max, node_hidden_size,\n",
    "                 num_prop_rounds):\n",
    "        super(DGMG, self).__init__(v_max)\n",
    "\n",
    "        # Graph embedding module\n",
    "        self.graph_embed = GraphEmbed(node_hidden_size)\n",
    "\n",
    "        # Graph propagation module\n",
    "        self.graph_prop = GraphProp(num_prop_rounds,\n",
    "                                    node_hidden_size)\n",
    "\n",
    "        # Actions\n",
    "        self.add_node_agent = AddNode(\n",
    "            self.graph_embed, node_hidden_size)\n",
    "        self.add_edge_agent = AddEdge(\n",
    "            self.graph_embed, node_hidden_size)\n",
    "        self.choose_dest_agent = ChooseDestAndUpdate(\n",
    "            self.graph_prop, node_hidden_size)\n",
    "\n",
    "        # Forward functions\n",
    "        self.forward_train = partial(forward_train, self=self)\n",
    "        self.forward_inference = partial(forward_inference, self=self)\n",
    "\n",
    "    @property\n",
    "    def action_step(self):\n",
    "        old_step_count = self.step_count\n",
    "        self.step_count += 1\n",
    "\n",
    "        return old_step_count\n",
    "\n",
    "    def prepare_for_train(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.add_node_agent.prepare_training()\n",
    "        self.add_edge_agent.prepare_training()\n",
    "        self.choose_dest_agent.prepare_training()\n",
    "\n",
    "    def add_node_and_update(self, a=None):\n",
    "        \"\"\"Decide if to add a new node.\n",
    "        If a new node should be added, update the graph.\"\"\"\n",
    "\n",
    "        return self.add_node_agent(self.g, a)\n",
    "\n",
    "    def add_edge_or_not(self, a=None):\n",
    "        \"\"\"Decide if a new edge should be added.\"\"\"\n",
    "\n",
    "        return self.add_edge_agent(self.g, a)\n",
    "\n",
    "    def choose_dest_and_update(self, a=None):\n",
    "        \"\"\"Choose destination and connect it to the latest node.\n",
    "        Add edges for both directions and update the graph.\"\"\"\n",
    "\n",
    "        self.choose_dest_agent(self.g, a)\n",
    "\n",
    "    def get_log_prob(self):\n",
    "        add_node_log_p = torch.cat(self.add_node_agent.log_prob).sum()\n",
    "        add_edge_log_p = torch.cat(self.add_edge_agent.log_prob).sum()\n",
    "        choose_dest_log_p = torch.cat(self.choose_dest_agent.log_prob).sum()\n",
    "        return add_node_log_p + add_edge_log_p + choose_dest_log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an animation where a graph is generated on the fly\n",
    "after every 10 batches of training for the first 400 batches. One\n",
    "can see how our model improves over time and begins generating cycles.\n",
    "\n",
    ".. figure:: https://user-images.githubusercontent.com/19576924/48929291-60fe3880-ef22-11e8-832a-fbe56656559a.gif\n",
    "   :alt:\n",
    "\n",
    "For generative models, we can evaluate its performance by checking the percentage\n",
    "of valid graphs among the graphs it generates on the fly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://s3.us-east-2.amazonaws.com/dgl.ai/model/dgmg_cycles-5a0c40be.pth\" to /home/honda/.torch/models/dgmg_cycles-5a0c40be.pth\n",
      "100%|██████████| 37972/37972 [00:00<00:00, 250553.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among 100 graphs generated, 98% are valid.\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "# Download a pre-trained model state dict for generating cycles with 10-20 nodes.\n",
    "state_dict = model_zoo.load_url('https://s3.us-east-2.amazonaws.com/dgl.ai/model/dgmg_cycles-5a0c40be.pth')\n",
    "model = DGMG(v_max=20, node_hidden_size=16, num_prop_rounds=2)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "def is_valid(g):\n",
    "    # Check if g is a cycle having 10-20 nodes.\n",
    "    def _get_previous(i, v_max):\n",
    "        if i == 0:\n",
    "            return v_max\n",
    "        else:\n",
    "            return i - 1\n",
    "\n",
    "    def _get_next(i, v_max):\n",
    "        if i == v_max:\n",
    "            return 0\n",
    "        else:\n",
    "            return i + 1\n",
    "\n",
    "    size = g.number_of_nodes()\n",
    "\n",
    "    if size < 10 or size > 20:\n",
    "        return False\n",
    "\n",
    "    for node in range(size):\n",
    "        neighbors = g.successors(node)\n",
    "\n",
    "        if len(neighbors) != 2:\n",
    "            return False\n",
    "\n",
    "        if _get_previous(node, size - 1) not in neighbors:\n",
    "            return False\n",
    "\n",
    "        if _get_next(node, size - 1) not in neighbors:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "num_valid = 0\n",
    "for i in range(100):\n",
    "    g = model()\n",
    "    num_valid += is_valid(g)\n",
    "\n",
    "del model\n",
    "print('Among 100 graphs generated, {}% are valid.'.format(num_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the complete implementation, see `dgl DGMG example\n",
    "<https://github.com/dmlc/dgl/tree/master/examples/pytorch/dgmg>`__.\n",
    "\n",
    "Batched Graph Generation\n",
    "---------------------------\n",
    "\n",
    "Speeding up DGMG is hard since each graph can be generated with a\n",
    "unique sequence of actions. One way to explore parallelism is to adopt\n",
    "asynchronous gradient descent with multiple processes. Each of them\n",
    "works on one graph at a time and the processes are loosely coordinated\n",
    "by a parameter server. This is the approach that the authors adopted\n",
    "and we can also use.\n",
    "\n",
    "DGL explores parallelism in the message-passing framework, on top of\n",
    "the framework-provided tensor operation. The earlier tutorial already\n",
    "does that in the message propagation and graph embedding phases, but\n",
    "only within one graph. For a batch of graphs, a for loop is then needed:\n",
    "\n",
    "::\n",
    "\n",
    "    for g in g_list:\n",
    "    self.graph_prop(g)\n",
    "\n",
    "We can modify the code to work on a batch of graphs at once by replacing\n",
    "these lines with the following. On CPU with a Mac machine, we instantly\n",
    "enjoy a 6~7x reduction for the graph propagation part.\n",
    "::\n",
    "\n",
    "    bg = dgl.batch(g_list)\n",
    "    self.graph_prop(bg)\n",
    "    g_list = dgl.unbatch(bg)\n",
    "\n",
    "We have already used this trick of calling ``dgl.batch`` in the\n",
    "`Tree-LSTM tutorial\n",
    "<http://docs.dgl.ai/tutorials/models/3_tree-lstm.html#sphx-glr-tutorials-models-3-tree-lstm-py>`__\n",
    ", and it is worth explaining one more time why this is so.\n",
    "\n",
    "By batching many small graphs, DGL internally maintains a large *container*\n",
    "graph (``BatchedDGLGraph``) over which ``update_all`` propels message-passing\n",
    "on all the edges and nodes.\n",
    "\n",
    "With ``dgl.batch``, we merge ``g_{1}, ..., g_{N}`` into one single giant\n",
    "graph consisting of $N$ isolated small graphs. For example, if we\n",
    "have two graphs with adjacency matrices\n",
    "\n",
    "::\n",
    "\n",
    "    [0, 1]\n",
    "    [1, 0]\n",
    "\n",
    "    [0, 1, 0]\n",
    "    [1, 0, 0]\n",
    "    [0, 1, 0]\n",
    "\n",
    "``dgl.batch`` simply gives a graph whose adjacency matrix is\n",
    "\n",
    "::\n",
    "\n",
    "    [0, 1, 0, 0, 0]\n",
    "    [1, 0, 0, 0, 0]\n",
    "    [0, 1, 0, 0, 0]\n",
    "    [1, 0, 0, 0, 0]\n",
    "    [0, 1, 0, 0, 0]\n",
    "\n",
    "In DGL, the message function is defined on the edges, thus batching scales\n",
    "the processing of edge user-defined functions (UDFs) linearly.\n",
    "\n",
    "The reduce UDFs (i.e ``dgmg_reduce``) works on nodes, and each of them may\n",
    "have different numbers of incoming edges. Using ``degree bucketing``, DGL\n",
    "internally groups nodes with the same in-degrees and calls reduce UDF once\n",
    "for each group. Thus, batching also reduces number of calls to these UDFs.\n",
    "\n",
    "The modification of the node/edge features of a ``BatchedDGLGraph`` object\n",
    "does not take effect on the features of the original small graphs, so we\n",
    "need to replace the old graph list with the new graph list\n",
    "``g_list = dgl.unbatch(bg)``.\n",
    "\n",
    "The complete code to the batched version can also be found in the example.\n",
    "On our testbed, we get roughly 2x speed up comparing to the previous implementation\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
